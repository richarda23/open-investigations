{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858d5b46-f1f8-4917-a36f-437e5e4f3d5a",
   "metadata": {},
   "source": [
    "# Extracting information from input in structured manner\n",
    "\n",
    "This notebook performs simple extraction of information about a coffee order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0671b-aacc-4884-86f9-5050cece5b2d",
   "metadata": {},
   "source": [
    "The usual boiler plate to import libraries and set the model.\n",
    "\n",
    "You'll need your OpenAI key set as environment variable `OPENAI_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75cfe7d7-a1bc-4f30-8915-21307e36d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored\n",
    "\n",
    "GPT_MODEL = \"gpt-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de03bc9-30fa-45b7-b4a1-ec8befd58fb1",
   "metadata": {},
   "source": [
    "This is is the usual function to make a call to ChatGPT API completetion endpoint, taking a list of messages \n",
    "and optionally a list of functions, and optionally an instruction to create arguments for a specified function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ab86f7-7612-4ce5-9f39-663e9898e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, functions=None, function_call=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    if function_call is not None:\n",
    "        json_data.update({\"function_call\": function_call})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47971b-4d90-4bf6-922a-f762f57eff0e",
   "metadata": {},
   "source": [
    "This function color codes the messages by role:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5456e8-08d7-4089-bf60-e6fcd747d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"yellow\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color['function']))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625e2dc0-06e8-4684-b41e-b453619f67c8",
   "metadata": {},
   "source": [
    "Next, we define the function arguments - the structured data we want to extract from the free text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32797540-490d-4164-b694-fa635db79175",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We could send this to an automated coffee machine\n",
    "def coffee (coffee_order):\n",
    "    print(f'Ordering coffee: {json.dumps(coffee_order, indent=2)}')\n",
    "\n",
    "## a dictionary of functions keyed by their name. \n",
    "available_functions = {\n",
    "    \"coffee\":coffee, \n",
    "}\n",
    "\n",
    "## The function definitions we will send to ChatGPT. The 'parameters' object is defined using JSON Schema.\n",
    "functions = [\n",
    "    {\n",
    "        \"name\" : \"coffee\",\n",
    "        \"description\": \" Get the coffee order from the input \",\n",
    "        \"parameters\" : {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\" : {\n",
    "                  \"order\": {\n",
    "                      \"type\":\"object\",\n",
    "                      \"properties\" : {\n",
    "                        \"coffee_type\": {\n",
    "                         \"type\":\"string\"\n",
    "                        }, \n",
    "                        \"temperature\": {\n",
    "                          \"type\":\"string\"\n",
    "                        },\n",
    "                        \"size\": {\n",
    "                          \"type\":\"string\"\n",
    "                        },\n",
    "                        \"milks\": {\n",
    "                          \"type\":\"string\"\n",
    "                        },\n",
    "                        \"sugar\": {\n",
    "                          \"type\":\"string\"\n",
    "                        },\n",
    "                        \"sugar_count\": {\n",
    "                          \"type\":\"number\"\n",
    "                        },\n",
    "                        \"syrups\": {\n",
    "                          \"type\":\"string\"\n",
    "                        }\n",
    "                    }         \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c63de082-38e5-4891-9afd-8820ad02ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    \"I'd like a tall cold latte please with 2 sugars and hazelnut syrup\",\n",
    "    \"What's the weather in London\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2f04ad-269c-4e0e-8c1f-ada72a1717c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33msystem: Extract user input into structured data\n",
      "\u001b[0m\n",
      "\u001b[32muser: I'd like a tall cold latte please with 2 sugars and hazelnut syrup\n",
      "\u001b[0m\n",
      "\u001b[35massistant: {'name': 'coffee', 'arguments': '{\\n  \"order\": {\\n    \"coffee_type\": \"latte\",\\n    \"temperature\": \"cold\",\\n    \"size\": \"tall\",\\n    \"sugar\": \"yes\",\\n    \"sugar_count\": 2,\\n    \"syrups\": \"hazelnut\"\\n  }\\n}'}\n",
      "\u001b[0m\n",
      "Ordering coffee: {\n",
      "  \"coffee_type\": \"latte\",\n",
      "  \"temperature\": \"cold\",\n",
      "  \"size\": \"tall\",\n",
      "  \"sugar\": \"yes\",\n",
      "  \"sugar_count\": 2,\n",
      "  \"syrups\": \"hazelnut\"\n",
      "}\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "\u001b[33msystem: Extract user input into structured data\n",
      "\u001b[0m\n",
      "\u001b[32muser: What's the weather in London\n",
      "\u001b[0m\n",
      "\u001b[34massistant: This query does not call for a coffee order extraction, hence no structured data needs to be output.\n",
      "\u001b[0m\n",
      "no function was returned\n",
      "-----------------------------------\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for input in inputs:\n",
    "    messages = [\n",
    "      {\n",
    "     \"role\":\"system\",\n",
    "     \"content\":\"Extract user input into structured data\"\n",
    "      }\n",
    "    ]\n",
    "    messages.append({\"role\":\"user\", \"content\" : input})\n",
    "    resp = chat_completion_request(messages, functions=functions)\n",
    "\n",
    "    response_message = resp.json()['choices'][0]['message']\n",
    "    \n",
    "    messages.append(response_message)\n",
    "    pretty_print_conversation(messages)\n",
    "    \n",
    "    if 'function_call' in response_message and response_message['function_call'] is not None:\n",
    "        to_call = response_message['function_call']['name']\n",
    "        f_args = json.loads(response_message['function_call']['arguments'])['order']\n",
    "        result = available_functions[to_call](f_args)\n",
    "\n",
    "    else:\n",
    "        print(f'no function was returned')\n",
    "    print ('-----------------------------------')\n",
    "    print ('-----------------------------------')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
