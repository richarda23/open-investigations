{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a4012b-3e1e-4dc3-bb57-cb02c6bdbfb4",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae0c26-4387-4b93-8391-861287dee846",
   "metadata": {},
   "source": [
    "This is based on https://learn.deeplearning.ai/langchain/lesson/4/chains lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d2554c3-bb64-4f26-93bd-79d80213f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.github import GitHubIssuesLoader\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GHA_TOKEN = os.getenv('GHA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f84269f-94b0-4b23-99ba-0c2316fc87f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory.buffer import ConversationBufferMemory\n",
    "chat_llm = ChatOpenAI(temperature=0.8)\n",
    "memory =ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f73c7-4553-4785-b1a0-2a28ece66c4d",
   "metadata": {},
   "source": [
    "LLM chain is one of the simplest and just connects a LLM and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81be2290-d3b1-4ddd-a273-02494a539613",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "\n",
    "{\"product\":\"Apple Mac\", \"review\": \"really excellent and fast\"},\n",
    "{\"product\":\"Windward isles bananas\", \"review\": \"fresh and tasty\"},\n",
    "{\"product\":\"Cat scarer\", \"review\": \"Didn't work, the cats paid it no attention\"},\n",
    "{\"product\":\"Dog collar\", \"review\": \"Our dog liked it but slipped his collar and escaped\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c462a0ae-cb28-40af-a6dd-a3d2f4acd34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "getCompanyNameT = PromptTemplate.from_template(\"For a product {product} think of a good company name in a {style} style\")\n",
    "chain = LLMChain(llm=chat_llm, prompt=getCompanyNameT,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a0f9f3c-9cbb-4252-bc68-dfe55224bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mFor a product Windward isles bananas think of a good company name in a jokey style\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Banana-nanza Inc.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(product=data[1]['product'], style=\"jokey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e132f-5c18-470c-8918-08576a175b15",
   "metadata": {},
   "source": [
    "The next is a simple sequential chain where we can put the output of 1 message into the input of the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f377de02-ab60-44af-a192-310352f23f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mFor a product Apple Mac think of a good company name in comedy style\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mFor a companyName iLaughMac think of a good tagline\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "## only works with single input and output\n",
    "getCompanyNameT = PromptTemplate.from_template(\"For a product {product} think of a good company name in comedy style\")\n",
    "getCompanyTaglineT = PromptTemplate.from_template(\"For a companyName {companyName} think of a good tagline\")\n",
    "## we don't need to worry about input/output names as there is only 1\n",
    "chain1 = LLMChain(llm=chat_llm, prompt=getCompanyNameT,verbose=True)\n",
    "chain2 = LLMChain(llm=chat_llm, prompt=getCompanyTaglineT,verbose=True)\n",
    "\n",
    "sequential_chain = SimpleSequentialChain(chains=[chain1, chain2])\n",
    "resp=sequential_chain.run(data[0]['product'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6f2101-fe2b-4d7c-91e2-454b4887210e",
   "metadata": {},
   "source": [
    "Question - how to get intermediate outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd43fb6b-e7c9-4782-b8be-ec01b1c3fcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Where humor meets innovation on your Mac!\"'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb69b51-d88b-404e-9c5a-b4ef93bf2cc6",
   "metadata": {},
   "source": [
    "Now let's use a regular Sequential Chain to use multiple inputs and outputs.\n",
    "We need to define the output keys of each subchain\n",
    "\n",
    "For the sequential chain wrapper we need to define the first 2 inputs and final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87a2ac0a-c1a0-4901-a607-61bc98e6bc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mFor a product Dog collar think of a good company name in silly style\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mFor a companyName Pawsome Puppers think of a good tagline\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mfor a tagline \"Unleash the Joy of Pawfect Companionship!\" return the sentiment which must be one of Positive, Neutral or Negative\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSummarise whether Pawsome Puppers with tagline\"Unleash the Joy of Pawfect Companionship!\" and sentiment Positive is a good name\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The name \"Pawsome Puppers\" with the tagline \"Unleash the Joy of Pawfect Companionship!\" has a positive sentiment and conveys a sense of fun and happiness. It suggests a focus on providing excellent companionship and enjoyable experiences with dogs. Overall, it can be considered a good name choice, as it effectively communicates the brand\\'s values and appeals to dog lovers.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "getCompanyNameT = PromptTemplate.from_template(\"For a product {product} think of a good company name in {style} style\")\n",
    "getCompanyTaglineT = PromptTemplate.from_template(\"For a companyName {companyName} think of a good tagline\")\n",
    "sentimentT = PromptTemplate.from_template(\"for a tagline {tagline} return the sentiment which must be one of Positive, Neutral or Negative\")\n",
    "summaryT = PromptTemplate.from_template(\"Summarise whether {companyName} with tagline {tagline} and sentiment {sentiment} is a good name\")\n",
    "\n",
    "llm_chain1 = LLMChain(llm=chat_llm, prompt=getCompanyNameT,verbose=True,output_key=\"companyName\")\n",
    "llm_chain2 = LLMChain(llm=chat_llm, prompt=getCompanyTaglineT,verbose=True, output_key=\"tagline\")\n",
    "llm_chain3 = LLMChain(llm=chat_llm, prompt=sentimentT,verbose=True, output_key=\"sentiment\")\n",
    "llm_chain4 = LLMChain(llm=chat_llm, prompt=summaryT,verbose=True, output_key=\"summary\")\n",
    "sub_chains = [llm_chain1,llm_chain2,llm_chain3,llm_chain4]\n",
    "seq_chain = SequentialChain(chains=sub_chains, input_variables=[\"product\", \"style\"],output_variables=[\"summary\"] )\n",
    "seq_chain.run(product=data[3]['product'], style=\"silly\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
