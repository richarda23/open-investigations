{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c713460-4415-4cea-b073-f8dc430288e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama; \n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.docstore.base import Document\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5dfb145-8e20-4665-b6f4-93cd2c16b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings()\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b1b4e10-216b-444a-a6f2-f5a94f3587dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into chunks \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=100)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2decb2-3399-4985-b68d-e838c19ff131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import ChromallEmbeddings\n",
    "from langchain.embeddings import OllamaEmbeddings # We can also try Ollama embeddings\n",
    "vectorstore = Chroma.from_documents(documents=all_splits,\n",
    "                                    embedding=OllamaEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b198da38-4f38-4266-9880-c005d88d5b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve\n",
    "question = \"How can Task Decomposition be done?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37448f28-1807-40e4-9687-f91c0b097e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e8cf250-5276-4541-a48e-39e9b135a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "QA_CHAIN_PROMPT = \"\"\"\n",
    "[INST]<<SYS>> You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.<</SYS>> \n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer: [/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581b1ae-4e87-41bd-93db-5efc5efc2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "llm = Ollama(model=\"llama2\",\n",
    "             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4464db57-ac6c-4b34-96de-f75c109a4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a joke about a {subject}\"\n",
    "pt = PromptTemplate(template=prompt, input_variables=[\"subject\"])\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt = pt)\n",
    "result = chain(\"potato\")\n",
    "\n",
    "eval = \"\"\" why this joke below funny? Explain the humour.\n",
    "   Joke: {joke}\n",
    "   \"\"\"\n",
    "print (result)\n",
    "eval_prompt = PromptTemplate(template= eval, input_variables=[\"joke\"])\n",
    "eval_chain = LLMChain(llm=llm, prompt=eval_prompt)\n",
    "eval_chain(result['text'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af1ceaef-aa88-4713-97dc-e7a39257e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "llm = Ollama(model=\"llama2\",\n",
    "             verbose=True)\n",
    "prompt = PromptTemplate(template= QA_CHAIN_PROMPT,input_variables=[\"question\", \"context\"])\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,retriever=vectorstore.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\":prompt}\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed686c9e-361b-4269-85b1-2fad712e989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the various approaches to Task Decomposition for AI Agents?\"\n",
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a16032f-66cb-4ef4-a206-fde980a4a853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the various approaches to Task Decomposition for AI Agents?',\n",
       " 'result': 'Task decomposition for AI agents involves breaking down complex tasks into smaller, more manageable sub-tasks that can be executed by the agent. There are various approaches to task decomposition, including:\\n\\n1. Divide and Conquer: This approach involves dividing a task into smaller sub-tasks, each of which can be executed independently. The results from each sub-task are then combined to achieve the overall goal.\\n2. Hierarchical Task Networks (HTN): This approach involves breaking down a task into a hierarchy of sub-tasks, with each level of the hierarchy representing a different level of detail or abstraction. The agent executes the tasks at each level in a hierarchical manner.\\n3. Workflow Nets: This approach involves modeling a task as a network of interconnected sub-tasks, with each sub-task representing a specific action or operation. The agent executes the tasks in a serial or parallel manner, depending on the workflow net architecture.\\n4. Planning: This approach involves using a planning algorithm to generate a sequence of actions that will achieve a specific goal. The agent uses the planned sequence of actions to execute the task.\\n5. Hybrid Approaches: Many AI agents use a combination of these approaches, tailoring their task decomposition strategy to the specific task and environment they are operating in.\\n\\nReferences:\\n\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.\" NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.\" arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\" arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.\" ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.\" arXiv preprint arXiv:2205.00445 (2022).\\n\\nThese references provide a comprehensive overview of the different approaches to task decomposition for AI agents, including the use of large language models, planning algorithms, and hybrid strategies.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
