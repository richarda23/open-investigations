{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc96fa0-3db9-4eb2-90d0-d32a8c420573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "walks_nb=182183\n",
    "generated_expts=1921314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607fe67c-dcab-453b-ac19-af2ee82f6c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rspace_loader import RSpaceLoader\n",
    "loader =RSpaceLoader(url=os.getenv(\"RSPACE_URL\"), api_key=os.getenv(\"RSPACE_API_KEY\"), folder_id=walks_nb)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f5a36a-78ec-49c5-b68b-8dbcb3f4ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap\n",
    "chain = load_summarize_chain(llm=chat_llm, verbose=True, chain_type=\"map_reduce\")\n",
    "output_summary = chain.run(docs)\n",
    "wrapped_text = textwrap.fill(output_summary, width=100)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb5bf4-345a-4523-8028-f6a44feb37c3",
   "metadata": {},
   "source": [
    "\n",
    "The above works very well, it does a good job at summarising. 3.5 turbo seems good, much faster than gpt4\n",
    "TODO:\n",
    " - do this in streamlit\n",
    " - input field for a notebook or folder id. Support global Id or normal ID\n",
    " - Load docs and summarise. Note how many docs there are (max 10)\n",
    " - generate summary of each doc\n",
    " - generate summary of summaries of folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b975118a-70c2-49a4-99e2-78da73e6dc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79522997-9089-40eb-9da1-567630db5076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores.utils import filter_complex_metadata\n",
    "from lan\n",
    "db = Chroma.from_documents(docs, OpenAIEmbeddings())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03ac38a-afde-4399-976d-efca4a7ffedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "pdfLoader = PyPDFLoader('./data/inc.pdf')\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=400)\n",
    "docs = pdfLoader.load_and_split(text_splitter=splitter);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0919ee99-d92c-44b1-bbc2-b37690b059b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sum(len(x.page_content) for x in docs)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a608a-89f1-492b-a8d8-1202f8f2a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "chat_llm = ChatOpenAI(temperature=0.0)\n",
    "prompt = \"\"\"\n",
    "    You are an expert in {research_area} research and will be given documents to summarise.\n",
    "    Please summarise the following text.\n",
    "    Try very hard to extract the key points.\n",
    "    Try very hard to not  repeat the text verbatim.\n",
    "    Your response must be less than one third of the length of the input text. Use bullet points and terse sentences.\n",
    "\n",
    "    Extract a maximum of 10 keywords and list these at the end in a section called 'Keywords'.\n",
    "    \n",
    "    The text:\n",
    "    \n",
    "    {text}\n",
    "    \n",
    "    Your summary:\n",
    "    \n",
    "    Your keywords (maximum 10):\n",
    "    \"\"\"\n",
    "promptT = PromptTemplate(input_variables=['text', 'research_area'],template=prompt)\n",
    "llm_chain = LLMChain(llm=chat_llm, prompt=promptT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124f4452-2215-470f-aafe-054c793ed111",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('polosummary-gpt4output.txt', 'r') as input:\n",
    "    lines = input.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc7646-5deb-4ce8-b6b7-421534e2a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.base import Document\n",
    "content  = [''.join(lines)]\n",
    "summarisedOnce = [Document(page_content=s1, metadata={'source':f\"page-{i}\"}) for i, s1 in enumerate(content)]\n",
    "summarisedAndSplit= splitter.split_documents(summarisedOnce)\n",
    "len(content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3795765d-a93f-4abc-9234-edadd5ce7a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e4f27-08e5-412b-a1dc-9065a350eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "outputs2 = []\n",
    "for d in docs:\n",
    "    resp = llm_chain.predict(text=d.page_content, research_area='biomedical')\n",
    "    outputs2.append(resp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab8b51-d13e-45b8-a5ed-b5b1ff8ec5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ''.join(outputs2)\n",
    "d2 = Document(page_content=t, metadata=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64219459-b92a-47d5-9549-1005514e27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_split =splitter.split_documents([d2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb36225-57f9-4404-8284-5405129d573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d505b47-1313-4259-b44f-f464ec40a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "outputs23 = []\n",
    "for d in d2_split:\n",
    "    resp = llm_chain.predict(text=d.page_content, research_area='biomedical')\n",
    "    outputs23.append(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3476f61e-cd25-41a9-bf59-b0665de84d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap\n",
    "chain = load_summarize_chain(llm=chat_llm, verbose=True, chain_type=\"map_reduce\")\n",
    "output_summary = chain.run(docs)\n",
    "wrapped_text = textwrap.fill(output_summary, width=100)\n",
    "print(wrapped_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
