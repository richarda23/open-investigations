{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d390c7-ec57-49c3-b59a-1fc7e0826dd5",
   "metadata": {},
   "source": [
    "## Generating Lucene Query Language queries from free text input\n",
    "\n",
    "This notebook takes text input, generates LQL queries and queries RSpace ELN API\n",
    "to retrieve documents.\n",
    "\n",
    "To run this you'll need:\n",
    "\n",
    "* An OpenAI API key\n",
    "* An account on https://community.researchspace.com, and an API key. (It's free to set up)\n",
    "* Python RSpace client - `pip install rspace_client`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3769571-abd1-47a7-9ed4-1b68b85b5118",
   "metadata": {},
   "source": [
    "Here we import everything we need and  check RSpace API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2dca6f-4671-47a3-a292-db7878ac7dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'OK', 'rspaceVersion': '1.91.1'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rspace_client.eln import eln\n",
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored\n",
    "\n",
    "eln_cli = eln.ELNClient(os.getenv(\"RSPACE_URL\"), os.getenv(\"RSPACE_API_KEY\"))\n",
    "print(eln_cli.get_status())\n",
    "GPT_MODEL = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edfb7b12-ee42-4344-bf57-71e085efdcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3b8fbe-a582-4853-b932-f19ace7c7743",
   "metadata": {},
   "source": [
    "Standard method to send messages to OpenAI's Chat completion API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f43ca3c-261e-497d-b25b-27af658b13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, functions=None, function_call=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    if function_call is not None:\n",
    "        json_data.update({\"function_call\": function_call})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d10244-d0c8-4eda-9657-208ceabc1b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the function that will be invoked with arguments generated by AI\n",
    "## It will make calls to RSpace's search API.\n",
    "def search_rspace_eln(luceneQuery, sort_order=\"lastModified desc\"):\n",
    "    q = \"l: \" + luceneQuery\n",
    "    docs = eln_cli.get_documents(query=q, order_by=sort_order)['documents']\n",
    "    wanted_keys = ['globalId','name', 'tags', 'created'] # The keys we want\n",
    "    summarised = list(map(lambda d: dict((k, d[k]) for k in wanted_keys if k in d), docs))\n",
    "    return summarised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b2a7342-ed8e-4132-93a9-95dd72ef33e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions = {\n",
    " \"lucene\":search_rspace_eln\n",
    "}\n",
    "\n",
    "functions = [\n",
    "  {\n",
    "    \"name\": \"lucene\",\n",
    "    \"description\": \"\"\"\n",
    "    A valid Lucene Query Language string generated from user input.\n",
    "    Document fields are name, docTag, fields.fieldData, and username.\n",
    "    Don't use wildcards.\n",
    "    \"\"\",\n",
    "    \"parameters\": {\n",
    "        \"type\":\"object\",\n",
    "        \"properties\": {\n",
    "            \"luceneQuery\": {\n",
    "                \"type\":\"string\",\n",
    "                \"description\":\"Valid Lucene Query Language as plain text\"\n",
    "            },\n",
    "            \"sort_order\": {\n",
    "                \"type\":\"string\",\n",
    "                \"description\":\"How results should be sorted\",\n",
    "                \"enum\":[\"name asc\", \"name desc\", \"created asc\", \"created desc\"]\n",
    "            },\n",
    "            \n",
    "        }\n",
    "    }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b6122d1-43a1-4cd0-a466-37009ca67d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    " {\n",
    "     \"role\" : \"system\",\n",
    "     \"content\": \"Generate function arguments from user input. Don't show reasoning.\"\n",
    " },\n",
    " {\n",
    "     \"role\" : \"user\",\n",
    "     \"content\": \"\"\"\n",
    "         I want to search for documents that are tagged with PCR but not ECL, \n",
    "         containing the phrase “DNA replication” but not \"RNA\"\n",
    "         List results in reverse alphabetical order\n",
    "         \"\"\"\n",
    " } \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e574166-0724-45ae-958e-14161457bc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Generate function arguments from user input. Don't show reasoning.\n",
      "\u001b[0m\n",
      "\u001b[32muser: \n",
      "         I want to search for documents that are tagged with PCR but not ECL, \n",
      "         containing the phrase “DNA replication” but not \"RNA\"\n",
      "         List results in reverse alphabetical order\n",
      "         \n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'lucene', 'arguments': '{\\n  \"luceneQuery\": \"docTag:PCR -docTag:ECL AND fields.fieldData:\\\\\"DNA replication\\\\\" -fields.fieldData:\\\\\"RNA\\\\\"\",\\n  \"sort_order\": \"name desc\"\\n}'}\n",
      "\u001b[0m\n",
      "[\n",
      "  {\n",
      "    \"globalId\": \"SD1924288\",\n",
      "    \"name\": \"aurora expression exit\",\n",
      "    \"tags\": \"polyclonal,PCR\",\n",
      "    \"created\": \"2023-09-15T23:47:26.853Z\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "resp = chat_completion_request(messages, functions, {'name':'lucene'})\n",
    "active_messages = messages\n",
    "response_message = resp.json()['choices'][0]['message']\n",
    "active_messages.append(response_message)\n",
    "\n",
    "if response_message['function_call'] is not None:\n",
    "    f_name = response_message['function_call']['name']\n",
    "    f_args = json.loads(response_message['function_call']['arguments'])\n",
    "    result = available_functions[f_name](**f_args)\n",
    "pretty_print_conversation(active_messages)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc9555f-99f6-4a3d-80e0-cb61aaf7a32e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
